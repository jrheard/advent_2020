day 7 is starting to finally get interesting / be worth taking notes on

the input looks like this

    light red bags contain 1 bright white bag, 2 muted yellow bags.
    dark orange bags contain 3 bright white bags, 4 muted yellow bags.
    bright white bags contain 1 shiny gold bag.
    muted yellow bags contain 2 shiny gold bags, 9 faded blue bags.
    shiny gold bags contain 1 dark olive bag, 2 vibrant plum bags.
    dark olive bags contain 3 faded blue bags, 4 dotted black bags.
    vibrant plum bags contain 5 faded blue bags, 6 dotted black bags.
    faded blue bags contain no other bags.
    dotted black bags contain no other bags.

the question is about finding out how many colors of bag can eventually contain a shiny gold bag

obvs i'll use a regex or two to parse the input
but the question is - parse it into what?

i'm initially thinking about a two-phase process
first i parse the input into a list of BagRules, where a BagRule looks like

BagRule
    color: str
    # a list of tuples like [(1, 'white'), (2, 'muted yellow')]
    contents: list[tuple[int, str]]

hm actually i think a dict would be better bc i'll be wanting to do fast lookups in that list
so a `bag_rules` dict of {color: contents}

and then i have a function that - does what?
hm

the function would either walk that dict (essentially a tree) from the top down, or from the bottom up
the top-down approach would be easiest but would be the most wasteful from a perf perspective
the bottom-up approach would be a bit more complicated to figure out i think, but should eliminate a lot of unnecessary work
so bottom-up

so, how do i solve this problem by walking the `bag_rules` dict from the bottom up?

i think i want to assemble a set of `colors_known_to_contain_shiny_gold`

TODO - is a dict really the right approach, or would a tree be better?
i guess the tree's root node would be empty, so it's really like a list of trees
anyway

bleh

ok so we walk the dict and find items like

    dark orange bags contain 3 bright white bags, 4 muted yellow bags.
    bright white bags contain 1 shiny gold bag.
    muted yellow bags contain 2 shiny gold bags, 9 faded blue bags.
    shiny gold bags contain 1 dark olive bag, 2 vibrant plum bags.

and then we insert 'bright white' and 'muted yellow' into the `known_to_contain_shiny_gold` set
and then at that point - hm

what if we do something like this

    # first step: initially populate known_to_contain_shiny_gold
    colors_known_to_contain_shiny_gold = set(
        color for color, contents in bag_rules.items()
        if any(bag_name == 'shiny gold' for _, bag_name in contents)
    )

    colors_to_check = set(
        color for color in bag_rules.keys()
        if color not in colors_known_to_contain_shiny_gold and color != 'shiny gold'
    )

and then like

    while colors_to_check:
        something

and what's the something? well actually i think it's look a lot like the initial population of `colors_known_to_contain_shiny_gold`
so that's interesting

so really actually we're constructing, like, two sets?
`colors_known_to_contain_shiny_gold` and `colors_to_scan_for`
and whenever we walk the contents of `bag_rules`, we always skip anything from `colors_known_to_contain_shiny_gold`

maybe i should just start getting into code at this point, starting w the regexes
actually nvm i dont need a regex

ok cool knocked it out
now it's day 10 part 2

    You glance back down at your bag and try to remember why you brought so many
    adapters; there must be more than a trillion valid ways to arrange them!
    Surely, there must be an efficient way to count the arrangements.

    What is the total number of distinct ways you can arrange the adapters to
    connect the charging outlet to your device?

they bold "more than a trillion" - def sounds like there should be some trick to this
i guess i could try solving it naively and go from there?

hm
well now i'm thinking

they give examples like

    (0), 1, 4, 5, 6, 7, 10, 11, 12, 15, 16, 19, (22)
    (0), 1, 4, 5, 6, 7, 10, 12, 15, 16, 19, (22)
    (0), 1, 4, 5, 7, 10, 11, 12, 15, 16, 19, (22)
    (0), 1, 4, 5, 7, 10, 12, 15, 16, 19, (22)
    (0), 1, 4, 6, 7, 10, 11, 12, 15, 16, 19, (22)
    (0), 1, 4, 6, 7, 10, 12, 15, 16, 19, (22)
    (0), 1, 4, 7, 10, 11, 12, 15, 16, 19, (22)
    (0), 1, 4, 7, 10, 12, 15, 16, 19, (22)

im having vague unformed thoughts about starting at the end and working backward
but not yet clear on how to structure that approach

but for instance notice that
    10, 11, 12, 15, 16, 19
    10, 12, 15, 16, 19

is the rightmost set of permutations
hm

so let's say we start at the right and work left
how do we detect that we've reached a point where multiple permutations are possible?

well let's say we're looking at index -1, 19
what are the three elements to the left of 19?
12, 15, 16
only one of those elements is three-or-less away from 19

and so on down the line until we get to 12

what are the three elements to the left of 12?
7, 10, 11
two of those elements are three-or-less away from 12

so the idea so far is that we start with the number 1
and every time we encounter a situation like this, we multiply it by `num_options` (in this example, 2)
and then we walk to the leftmost valid number to continue from (in this example, 10) and keep going

so let's try that

no, too low - came up with 172186884 but that's less than a trillion

here's what i tried:

    def num_available_adapters(adapter_joltages: list[int]) -> int:
        return sum(
            1 for joltage in adapter_joltages[1:4] if adapter_joltages[0] - joltage <= 3
        )


    def part_2() -> int:
        joltages = sorted(load_input(), reverse=True)

        num_permutations = 1

        while joltages != [0]:
            num_available = num_available_adapters(joltages)
            num_permutations *= num_available
            joltages = joltages[num_available:]

        return num_permutations

so why doesn't this give the right answer?

let's try it on the example data

hm
i think i'm jumping too far to the right

i think the right answer is going to be 2**something

hm hm hm

ok let's work through some more examples to find a pattern

1,2,3,4,5,6
1,2,3,4,6

you use the 5 or you dont
    scenario with the 5:

    1,2,3,4,5
    1,2,3,5

    you use the 4 or you dont
        etc

    scenario without the 5:

    1,2,3,4
    1,2,4

    you use the 3 or you dont
        etc

sure looks recursive

so at the point where we're deciding whether or not to use the 5, we have two options
hm
it feels like maybe the answer is 2 ** num_times_we_had_a_choice
no, it's not always a power of 2, 19208 isn't a power of 2

ugh this is kicking my ass
ok let's go back to their examples

(0), 1, 4, 5, 6, 7, 10, 11, 12, 15, 16, 19, (22)
(0), 1, 4, 5, 6, 7, 10, 12, 15, 16, 19, (22)
(0), 1, 4, 5, 7, 10, 11, 12, 15, 16, 19, (22)
(0), 1, 4, 5, 7, 10, 12, 15, 16, 19, (22)
(0), 1, 4, 6, 7, 10, 11, 12, 15, 16, 19, (22)
(0), 1, 4, 6, 7, 10, 12, 15, 16, 19, (22)
(0), 1, 4, 7, 10, 11, 12, 15, 16, 19, (22)
(0), 1, 4, 7, 10, 12, 15, 16, 19, (22)

so they're going left to right, prob doesnt matter either way

first decision point is - you either use the 5 or you dont
using the 5:

    (0), 1, 4, 5, 6, 7, 10, 11, 12, 15, 16, 19, (22)
    (0), 1, 4, 5, 6, 7, 10, 12, 15, 16, 19, (22)
    (0), 1, 4, 5, 7, 10, 11, 12, 15, 16, 19, (22)
    (0), 1, 4, 5, 7, 10, 12, 15, 16, 19, (22)

    you either use the 6 or you dont
    using the 6:

        (0), 1, 4, 5, 6, 7, 10, 11, 12, 15, 16, 19, (22)
        (0), 1, 4, 5, 6, 7, 10, 12, 15, 16, 19, (22)

        you either use the 11 or you dont
        using the 11:
            (0), 1, 4, 5, 6, 7, 10, 11, 12, 15, 16, 19, (22)
        not using the 11:
            (0), 1, 4, 5, 6, 7, 10, 12, 15, 16, 19, (22)

    not using the 6:

        you either use the 11 or you dont
        using the 11:
            (0), 1, 4, 5, 7, 10, 11, 12, 15, 16, 19, (22)
        not using the 11:
            (0), 1, 4, 5, 7, 10, 12, 15, 16, 19, (22)


not using the 5:
    (not expanding this one)

    (0), 1, 4, 6, 7, 10, 11, 12, 15, 16, 19, (22)
    (0), 1, 4, 6, 7, 10, 12, 15, 16, 19, (22)
    (0), 1, 4, 7, 10, 11, 12, 15, 16, 19, (22)
    (0), 1, 4, 7, 10, 12, 15, 16, 19, (22)

hrm hrm hrm
at the end of the day there are three decision points
the 5, the 6, the 11

at the 5 level, there are 4 options + 4 options
at the 6 level, there are 2 options + 2 options
at the 11 level, there are 1 option + 1 option

so i'm like

do we count the number of decision points
and then do like

if num_decision_points == 1:
    return 1

result = 0
for i in range(num_decision_points:)
    result = something

this first example is too small to generalize on, let's use the other one
this one keeps going for ages, has 19208 permutations

(0), 1, 2, 3, 4, 7, 8, 9, 10, 11, 14, 17, 18, 19, 20, 23, 24, 25, 28, 31, 32, 33, 34, 35, 38, 39, 42, 45, 46, 47, 48, 49, (52)
(0), 1, 2, 3, 4, 7, 8, 9, 10, 11, 14, 17, 18, 19, 20, 23, 24, 25, 28, 31, 32, 33, 34, 35, 38, 39, 42, 45, 46, 47, 49, (52)
(0), 1, 2, 3, 4, 7, 8, 9, 10, 11, 14, 17, 18, 19, 20, 23, 24, 25, 28, 31, 32, 33, 34, 35, 38, 39, 42, 45, 46, 48, 49, (52)
(0), 1, 2, 3, 4, 7, 8, 9, 10, 11, 14, 17, 18, 19, 20, 23, 24, 25, 28, 31, 32, 33, 34, 35, 38, 39, 42, 45, 46, 49, (52)
(0), 1, 2, 3, 4, 7, 8, 9, 10, 11, 14, 17, 18, 19, 20, 23, 24, 25, 28, 31, 32, 33, 34, 35, 38, 39, 42, 45, 47, 48, 49, (52)
(0), 3, 4, 7, 10, 11, 14, 17, 20, 23, 25, 28, 31, 34, 35, 38, 39, 42, 45, 46, 48, 49, (52)
(0), 3, 4, 7, 10, 11, 14, 17, 20, 23, 25, 28, 31, 34, 35, 38, 39, 42, 45, 46, 49, (52)
(0), 3, 4, 7, 10, 11, 14, 17, 20, 23, 25, 28, 31, 34, 35, 38, 39, 42, 45, 47, 48, 49, (52)
(0), 3, 4, 7, 10, 11, 14, 17, 20, 23, 25, 28, 31, 34, 35, 38, 39, 42, 45, 47, 49, (52)
(0), 3, 4, 7, 10, 11, 14, 17, 20, 23, 25, 28, 31, 34, 35, 38, 39, 42, 45, 48, 49, (52)

so here's an example of a decision point
2,4,5

and here are some non-examples
2,4,6
2,5

it's a point where adapters[i+2] <= 3
cool so let's write a function that counts the number of decision points

ugh i dunno man
the function says there are 15 decision points in the long example
which matches up my manual mental count just now, assuming my "decision points" definition/approach is reasonable
but so like
what do i do with that?

the right answer is 19208
but 2 ** 14 is 16384

hrm
math is hard

gotta go for the day, if i dont come up with an answer to this one im just gonna look it up and move on;
i wanna get programming practice, not math practice (although it sure would be nice if i could come up w this one myself)

ok so now im doin day 11
implementation is going fine so far, its game of life
but my first pass implementation isn't converging the way they say it should

guess i gotta make a print method

hm
it looks like seats are going from floor to non-floor
which should never happen
how's that happening?

    #.LL.L#.##
    #LLLLLL.L#
    L.L.L..L..
    #LLL.LL.L#
    #.LL.LL.LL
    #.LLLL#.##
    ..L.L.....
    #LLLLLLLL#
    #.LLLLLL.L
    #.#LLLL.##

    ##L###.###
    .L.L...L..
    ########L#
    ##.###.#LL
    .##..#####
    LL.#LL.###
    #L.#L#.###
    ..#....#L.
    #L.LL#.L.#
    ##.#L#.#L#

something wrong with my print method?
if not, where?

hm
it looks like i was doing

    for x in range(0, self.height):
        for y in range(0, self.width):

instead of

    for y in range(0, self.height):
        for x in range(0, self.width):

why should that have made a difference?
because it was causing the resulting seats to be appended to the new grid in the wrong order

ok cool neat
so now i'm working on day 13 part 2

this bus ids and indexes stuff
bit of a weird problem

my initial idea here is to find the bus with the largest ID
i feel like that must have a big influence on the shape of the desired timestamp

let's say the biggest id is 853
and its index is 17
then the timestamp will need to be a multiple of 836 (853 - 17)

is this, like, a factorization problem?

anyway let's see if that bears out by looking at one of their examples

    1789,37,47,1889 first occurs at timestamp 1202161486.

1889 is at index 3
timestamp must be a multiple of 1886 then?

>>> 1202161486 % 1886
568

nope
bleh

>>> 1202161486 % 1889
1886

hm
that's interesting

timestamp must be (a multiple of bus id) - bus_index?

let's try another example

    67,7,x,59,61 first occurs at timestamp 1261476.

biggest id 67 at index 0

>>> 1261476 % 67
0

let's try one where index isn't 0

    The earliest timestamp that matches the list 17,x,13,19 is 3417.

id 19 at index 3

>>> 3417 % 19
16

ok cool so it IS the case that the largest bus id and its index are a constraint on the timestamp
makes sense

so can we say anything about the second-largest? like a general statement about how it influences the timestamp?

    67,7,x,59,61 first occurs at timestamp 1261476.

second-largest is 61 at index 4

>>> 1261476 % 61
57

cool so it looks like that property holds for all bus ids
the timestamp must be (a multiple of the bus id) - bus_index

so uh
how can we use that?

i guess i could generate an infinite list of valid numbers for the largest bus
and then for each number in the list, validate it against the other bus ids

ok so i wrote that but it's pretty slow
not really sure what to do to speed it up, will think about it

ok so let's try this again
the target number has these properties:
for each bus id and index:
    the number is (a multiple of the bus id) - the index

so what if we just assemble that number by hand and see if it's the smallest?
i dont think it'll be the smallest but can't hurt to check

yeah, no dice

def part_2() -> int:
    result = 1
    for index, bus_id in load_indexes_and_bus_ids():
        result = result * bus_id - index

    return result

2245654873698359

aoc says the answer is too high

i think i'm gonna look this one up too

https://0xdf.gitlab.io/adventofcode2020/13
_this_ guy got stuck too, says this is number theory stuff
whee

ok now it's day 17, 3d game of life

    Before any cycles:

    z=0
    .#.
    ..#
    ###


    After 1 cycle:

    z=-1
    #..
    ..#
    .#.

    z=0
    #.#
    .##
    .#.

    z=1
    #..
    ..#
    .#.

i don't understand why in this example, the "after 1 cycle" doesn't have 4 rows at z=0

ugh whyy

oh wait
does it lose a row at thet op???
let's do this by hand

    .#.
    ..#
    ###

    becomes

    ...
    #.#
    .##
    .#.

ok yeah cool
good! ok phew
ok so now i can implement

ok day 18

going back and forth about whether or not i should use some kind of tree data structure

or just a recursive function that evaluates strings
leaning toward the recursive fn

hm
so i feel like the recursive fn wants to evaluate the leftmost thing
whether that's a bare number or a parenthesized expression

hm hm hm
ok so hm
what if i did like two passes
one pass to do the parentheses
and another pass to go left-to-right

hm no hm
this is tricky bc the recursive fn approach makes it so that the equation is evaluated basically right-to-left
which i dont want

ugh tree or not? hm

noodling about a recursive pass followed by a left-to-right pass
hm

ok trying out a tree


    print(parse_expression_string("2 * 3 + (4 * 5)", 0))
    Expression(left=2, right=Expression(left=3,
    right=Expression(left=Expression(left=4, right=Expression(left=5,
    right=None, operator=None, parentheses_depth=1), operator='*',
    parentheses_depth=1), right=None, operator=None, parentheses_depth=0),
    operator='+', parentheses_depth=0), operator='*', parentheses_depth=0)

can i work with this?
maybe

first: find the head of the expression with the greatest nonzero parentheses depth
second: evaluate it in a nonrecursive way, asserting along the way that all .left values are ints
maybe a while loop?

ok cool
so at this point i have a fn for parsing a string into an expression tree
and i have a fn for evaluating a "leaf" expression
now i need a fn that takes an expression and recursively replaces the deepest parenthesized expression with an int
until there are no parenthesized expressions left

man
i really feel like i'm overcomplicating this
maybe rewinding and trying some sort of stack-based approach could be better
i dunno

at the end of the day i'm always gonna want to transform an input string into some data structure
and then recursively replace the deepest parenthesized expressions in that data structure with the ints that they evaluate to
and i'm not sure how a list+string-based approach would be better than this Expression thing,
bc parenthesized expressions can appear anywhere

ok i made a bunch of progress but still kinda getting my butt kicked
almost tempted to do two passes here too
one find_deepest_parentheses_depth fn
and another find_parent_of_node_with_depth(depth: int) fn

i feel like that'd be easier to get right
but let's keep that in the back pocket for now
frick it im gonna just go w that

finished, it's way overengineered, could have just done it w a string based approach, but oh well
this was good practice in working w trees :) even if it was an objectively worse implementation than what other people did

day 19 looks fun! dependency graph of some kind maybe?
trees again? :) :) :)

or do i just throw these rules all in a dict and keep them as strings and evaluate them on the fly?

hm
this is an interesting one
first pass of implementing on-the-fly solution seems relatively straightforward so far
but i'm concerned about perf and recursion depth

we'll have to see i guess
the other approach would be to eagerly compute a big set of all valid strings based on just the rules themselves
seems like it'd be pretty crazy memory wise though and i dunno that it would buy us much perf either

ok so i'm making progress on initial implementation of 19 part 1
looking good so far impl wise, code is simple enough
but not working yet, let's see why

    checking chunked_string=['a', 'babb', 'b'] against sub_rules=['4', '1', '5']

let's add some manual calls

oh lol my leaf comparison was wrong
it was comparing a to "a", not a to a
ez fix

ok it solves the example input easily enough
let's try it on the real input
bit nervous

ok yeah this is taking a long time
might have to go w a different implementation
trying @lru_cache rq just in case

yeah no dice
ok so so far i've been trying an approach where i check each input string against the rules dict at runtime
and like come up w all the possible permutations of the string a million times at each level
which is not working

so instead i think i should try first evaluating the RULES to come up with the set of all the strings that they allow for

ok, so
how do i eagerly evaluate these rules?
what algo + data structures?

keep the dict for now
the dict is like implicitly a tree i think?
anyway

hm
interesting
i feel like a substitution approach similar to the one from day 18 could be useful here
but like in the other direction
instead of collapsing parens into ints, i want to expand non-leaf rules into leaf rules
except that instead of having one giant huge string like "4 1 5 3 2 9 | 2 3 4 2 5 9 | 2 1 3 5 9",
i think i'd prefer a list of strings like ["4 1 5 3 2 9", "2 3 4 2 5 9", "2 1 3 5 9]
or maybe even lists of lists of chars? hm

argh frick

i was working on that eager evaluation guy and ended up with

Traceback (most recent call last):
  File "/Users/jrheard/Dropbox/dev/advent_2020/day_19.py", line 106, in <module>
    print(part_1())
          ^^^^^^^^
  File "/Users/jrheard/Dropbox/dev/advent_2020/day_19.py", line 96, in part_1
    print(list(expand_rule_string("0", rules, leaf_rules)))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jrheard/Dropbox/dev/advent_2020/day_19.py", line 70, in expand_rule_string
    for string in expand_rule_string(possible_rule_string, rules, leaf_rules):
  File "/Users/jrheard/Dropbox/dev/advent_2020/day_19.py", line 70, in expand_rule_string
    for string in expand_rule_string(possible_rule_string, rules, leaf_rules):
  File "/Users/jrheard/Dropbox/dev/advent_2020/day_19.py", line 70, in expand_rule_string
    for string in expand_rule_string(possible_rule_string, rules, leaf_rules):
  [Previous line repeated 994 more times]
  File "/Users/jrheard/Dropbox/dev/advent_2020/day_19.py", line 64, in expand_rule_string
    if all(sub_rule in leaf_rules for sub_rule in sub_rules):
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RecursionError: maximum recursion depth exceeded

is there a part where i'm not narrowing the stuff i'm passing into the recursive call enough?

yeah whoops fixed

ok i got this working on part 1, which is amazing
part 2 looks like it could be tricky

maybe it'll give me a better idea for a way to do part 1 too, we'll see

    completely replace rules 8: 42 and 11: 42 31 with the following:

    8: 42 | 42 8
    11: 42 31 | 42 11 31

    This small change has a big impact: now, the rules do contain loops, and the
    list of messages they could hypothetically match is infinite. You'll need to
    determine how these changes affect which messages are valid.

    Fortunately, many of the rules are unaffected by this change; it might help to
    start by looking at which rules always match the same set of values and how
    those rules (especially rules 42 and 31) are used by the new versions of rules 8
    and 11.

ok, let's see

    42: 109 86 | 66 52
    31: 52 70 | 86 126

hm what if i just run my thing on those rules

    42: {'aabbabba', 'bbbbbaaa', 'bbaabbaa', 'abbababb', 'abbbbaab', 'abaaaaba', 'abbbabbb', 'aaaaaaab', 'baaaabaa', 'bbbbaaba', 'abbbbbab', 'aabbabab', 'bbabbaab', 'aabaabba', 'babbbaba', 'bbbabaab', 'babbbaab', 'abbaabbb', 'bbaababb', 'bbaaaaba', 'abbaabaa', 'abbabbaa', 'bbabbaba', 'ababbaba', 'baababbb', 'babbbaaa', 'aababbaa', 'bababbab', 'abaabaab', 'bbabaaba', 'baabbaab', 'baaaabba', 'aabbbbba', 'bbabbaaa', 'bbababba', 'bbbaaaba', 'bbababab', 'aaaaaabb', 'aaaabbba', 'babaaabb', 'abbbbaaa', 'bbbaaabb', 'baabbbbb', 'aababbab', 'babbaaab', 'abaaaaaa', 'abbaaabb', 'bbbbbbba', 'aaaababb', 'bbaaabaa', 'aabbbbbb', 'abaaabbb', 'abbababa', 'abbabaaa', 'aabaabab', 'bbabaabb', 'baababba', 'babbaaaa', 'aaababbb', 'abbabaab', 'aaaabbbb', 'aabbbaab', 'bbbbbabb', 'baabbaba', 'aabbbbab', 'bbbabaaa', 'aabbaaaa', 'bbaabbab', 'bbaaaaaa', 'bbbbabab', 'baabaabb', 'ababbbbb', 'bababbaa', 'abaabbab', 'ababaaaa', 'aababaaa', 'baaabaaa', 'aaaaaaaa', 'aaabbaab', 'aaaaabab', 'baaabbba', 'ababaaba', 'baabbbab', 'aabbbbaa', 'abbabbab', 'babbabaa', 'abababaa', 'abbbaaaa', 'aaaaabba', 'baababaa', 'bbbbbbbb', 'bbabbabb', 'aabbabaa', 'baaabaab', 'aaaaabbb', 'aaababba', 'bbbaabba', 'bbbbaabb', 'aabbbaba', 'aaaabbab', 'bbabaaab', 'abbbbbaa', 'aaaabaaa', 'bbbbaaab', 'babaaaba', 'aabaabaa', 'baababab', 'bbbabbab', 'babbabba', 'aaabaaab', 'aabaaaba', 'baaabbbb', 'aaababaa', 'babbaaba', 'baabbbba', 'bbaababa', 'bbaaabab', 'bbabbbba', 'bbbababb', 'abbaaaaa', 'aababaab', 'bbabbbaa', 'bbbbbbaa', 'aaaabaab', 'bababaaa', 'bbabbbbb', 'aaaababa', 'aabaabbb'}
    31: {'baabbaaa', 'babaabba', 'abbaabba', 'babbabbb', 'aababbbb', 'abbaaaba', 'baaaaaba', 'babaaaab', 'abaababb', 'ababbbba', 'baaabbab', 'babbabab', 'bbaabbba', 'babaabaa', 'ababaabb', 'aaaaaaba', 'bbbbbaab', 'abbbaaab', 'aaabbbba', 'aabaaaaa', 'ababbbab', 'baabbbaa', 'baaababb', 'baabaaaa', 'aaaaabaa', 'abaaaabb', 'bbababbb', 'babaabbb', 'abaabaaa', 'bbbaaaaa', 'bbababaa', 'bbaabaab', 'aabaaaab', 'abaabbbb', 'abaabbba', 'abbabbba', 'ababaaab', 'bbbabbbb', 'baabaaba', 'bbbaabbb', 'babbbbab', 'aaabbaaa', 'babbbabb', 'abbbbbbb', 'bbaaaaab', 'abbbbaba', 'bababaab', 'abbabbbb', 'baaaaaaa', 'abbbaaba', 'abaaabaa', 'aaabaabb', 'babaaaaa', 'aabbaaba', 'bbbabbaa', 'bababbba', 'aabababa', 'aaabbabb', 'bbbbabbb', 'abaaabba', 'abbaabab', 'bbbbbaba', 'bbaaabbb', 'aaabaaba', 'babbaabb', 'baaaaabb', 'bbbbabba', 'abababbb', 'aabbaaab', 'baabaaab', 'aaabbbaa', 'bbbaabaa', 'aabaaabb', 'bbbaaaab', 'baaaabab', 'abbbabba', 'bbaaabba', 'babaabab', 'abaaabab', 'aaabbbab', 'abaababa', 'ababbaaa', 'bbbbaaaa', 'abbbabab', 'aabbabbb', 'bbabaaaa', 'baaababa', 'babbbbbb', 'bbbababa', 'bbaabaaa', 'aababbba', 'aabbaabb', 'aabbbaaa', 'aabababb', 'bbaaaabb', 'ababbbaa', 'bbbaabab', 'bababbbb', 'baaaabbb', 'babababb', 'abababba', 'babababa', 'ababbaab', 'bbaabbbb', 'babbbbba', 'baaabbaa', 'abbbaabb', 'bbabbbab', 'bbbabbba', 'abaaaaab', 'abbbabaa', 'abbbbbba', 'aaaabbaa', 'ababbabb', 'babbbbaa', 'abaabbaa', 'abbbbabb', 'aaababab', 'bbbbabaa', 'aaabbbbb', 'baaaaaab', 'baabbabb', 'abababab', 'aabbbabb', 'aaabaaaa', 'abbaaaab', 'bbbbbbab', 'aaabbaba'}

ok
so 8 is basically saying that either the string has to be in 42's set,
or that for each chunk of 8 chars in the string,
that chunk has to be in 42's set
seems doable

and 11 is saying that the string has to either be a chunk that's in 42's set followed by a chunk that's in 31's set,
or it has to be 42 11 31
interesting interesting

hm
hm hm hm
the tricky thing here is that
right now my implementation takes the rules dict and returns a set of strings
so it's like fully eager
but instead, now it's going to have to be partially eager and partially lazy
hm

hmmmmmm.
maybe my implementation can return a set of strings and a set of regexes?
do a lot of rules use 8 and 11?

lol just 0

    0: 8 11

does that help? i feel like it should help

yeah ok i'm implementing fns for 8 and 11

implementation was fine but my version is too strict
prob a bug somewhere
retooling my impl to work on their sample data

    31: {'bbbaa', 'abbaa', 'abaaa', 'abaab', 'baaba', 'baaab', 'abbba', 'ababb', 'babab', 'aabaa', 'abbab', 'aabba', 'babba', 'aabab', 'babaa', 'bbaba'}
    42: {'abbbb', 'aaaab', 'aaabb', 'ababa', 'bbbba', 'aaaba', 'bbaab', 'bbbab', 'aaaaa', 'baaaa', 'bbbbb', 'bbaaa', 'babbb', 'baabb', 'bbabb', 'aabbb'}

ok mine works on their sample data now
but still doesn't give the right answer for my input
gives 386, which they say is too high and "curiously, is the right answer for someone else" lol

i wish my thing didn't work on their sample so that i could debug it more easily
difficult to debug when i don't know what the right answer is
just gotta reread the code+prompt a bunch i guess

ok im adding some prints

    rule_31_strings={'abaababb', 'abaabbba', 'abbabbba', 'abaaabba', 'aababbbb', 'bbaaabbb', 'babababa', 'bbbabbaa', 'baaaabab', 'aaabbaba', 'abbbaaba', 'abaabbaa', 'abbbbabb', 'ababaaab', 'babbbabb', 'aaabaaaa', 'aabaaaab', 'bbbabbbb', 'bbaabaab', 'bbabbbab', 'aaabbbaa', 'abaaabab', 'babbbbba', 'babaaaaa', 'bbaaaaab', 'bbbaabab', 'bbbbbaba', 'babaaaab', 'abbbaaab', 'aabbaaba', 'babaabba', 'aaabaaba', 'babbabbb', 'aabaaaaa', 'aababbba', 'bbbbbbab', 'abbaaaab', 'aaabaabb', 'abababba', 'bababbbb', 'aabaaabb', 'abababab', 'ababbbab', 'bbbababa', 'baabbabb', 'bbaaaabb', 'baabaaaa', 'aaaaabaa', 'baabaaba', 'baaaaabb', 'baabbbaa', 'baaabbaa', 'ababbbba', 'aabababa', 'bbbaaaab', 'baabaaab', 'babaabab', 'abaabbbb', 'abaababa', 'aaabbaaa', 'baaaaaaa', 'bbbbabba', 'bbababbb', 'aaabbbbb', 'babbbbbb', 'ababbabb', 'abbabbbb', 'bbbaaaaa', 'bbbbabbb', 'bbbaabbb', 'babbaabb', 'aabbbaaa', 'abbaaaba', 'aaabbbab', 'bbbbbaab', 'ababbaaa', 'abbbabaa', 'bbaabbbb', 'babaabaa', 'bababaab', 'aaaaaaba', 'abaaabaa', 'baabbaaa', 'bbaabbba', 'ababbbaa', 'abbaabab', 'babbabab', 'baaaabbb', 'abababbb', 'aaabbbba', 'bbbabbba', 'bababbba', 'abbbbaba', 'ababaabb', 'bbaaabba', 'aaabbabb', 'aabbaaab', 'bbabaaaa', 'abbbbbba', 'baaaaaab', 'abbaabba', 'babababb', 'bbaabaaa', 'baaababb', 'abbbaabb', 'babbbbaa', 'ababbaab', 'aabbbabb', 'baaabbab', 'aabbaabb', 'bbbbaaaa', 'abaabaaa', 'abaaaabb', 'baaababa', 'abbbabba', 'aabbabbb', 'abbbbbbb', 'abbbabab', 'aaababab', 'babaabbb', 'babbbbab', 'bbbbabaa', 'bbababaa', 'abaaaaab', 'bbbaabaa', 'aaaabbaa', 'aabababb', 'baaaaaba'}
    rule_42_strings={'baaaabba', 'babbbaab', 'abbabbab', 'aaaaabbb', 'baababab', 'bbbbbbaa', 'babbbaaa', 'bababbab', 'aababaaa', 'bbbaaaba', 'bbabbbba', 'aaababaa', 'abbbbbaa', 'bbaaaaba', 'baabbaba', 'aabbaaaa', 'abaabaab', 'bbabaaba', 'babbbaba', 'aaaabbab', 'baaabaab', 'aaaabaab', 'abaabbab', 'aabbbbab', 'bbaaabaa', 'baababaa', 'baaabaaa', 'bbabaaab', 'aabaabaa', 'baabbbba', 'abbaaabb', 'abbbabbb', 'babbabaa', 'aabbabba', 'bbaababb', 'abaaaaba', 'aaaaabba', 'baabaabb', 'baaaabaa', 'bbbababb', 'aabbabab', 'bbabbbaa', 'abababaa', 'aabaabba', 'abbabaab', 'bbabaabb', 'aababbab', 'babbabba', 'aabbbaab', 'abbbaaaa', 'bbabbaaa', 'aabbabaa', 'ababaaba', 'aabbbbaa', 'abbaabaa', 'baabbbbb', 'bbbabaab', 'babbaaba', 'bbaabbab', 'aaababbb', 'baabbaab', 'bbbbbabb', 'bbaaaaaa', 'baaabbbb', 'aaaababa', 'abbbbaab', 'bbbaabba', 'bbbbbbba', 'ababbaba', 'abbaabbb', 'baababbb', 'abbababb', 'bbaabbaa', 'abbabaaa', 'bbbaaabb', 'aaabbaab', 'babbaaaa', 'babbaaab', 'aababaab', 'bbbbbbbb', 'bbbbabab', 'aaaaaabb', 'bababaaa', 'bbabbaba', 'aabbbaba', 'bbaababa', 'aabbbbbb', 'aaaabbbb', 'aaaaaaaa', 'babaaaba', 'bbbabbab', 'aabaabbb', 'aaaaabab', 'aaaababb', 'babaaabb', 'aaaabbba', 'bbababab', 'bbbbaaba', 'abbbbaaa', 'bbbbaaab', 'abbabbaa', 'bbaaabab', 'aabbbbba', 'bbbbaabb', 'baabbbab', 'aabaabab', 'bbbabaaa', 'bbabbabb', 'baaabbba', 'aabaaaba', 'abbbbbab', 'ababbbbb', 'bbababba', 'aababbaa', 'bababbaa', 'abbaaaaa', 'aaaaaaab', 'bbbbbaaa', 'abbababa', 'ababaaaa', 'aaaabaaa', 'baababba', 'abaaaaaa', 'aaababba', 'abaaabbb', 'aaabaaab', 'bbabbbbb', 'bbabbaab'}

    does_match? string='bbbababaabaabaabababbbabaababababbabbbbabbabaabababbbaabbbbaaababbbbbaabbaaaaaab'
    A: string='' matches rule 8
    does_match? string='ababbbbbaaabbbababaabaababaabaaabbbaaabaaaaaabbbabbbaabababbabab'
    A: string='' matches rule 8
    A: string='ababbbbb' matches rule 8
    does_match? string='aaabbabbababaaababbaaabaaabbaaabbababbbb'
    A: string='' matches rule 8
    does_match? string='aaaababbbbbbaabbbbabaabaaaaaabbaabbbbbabaaabbbaabaabbbaaabaabbbbaaabaaaa'
    A: string='' matches rule 8
    A: string='aaaababb' matches rule 8
    B: string='abbbbbabaaabbbaa' matches rule 11
    does_match? string='aaababaabababbabababbaaa'
    A: string='' matches rule 8
    A: string='aaababaa' matches rule 8
    B: string='bababbabababbaaa' matches rule 11
    does_match? string='abababaaabbabbaaaaaabaaaaaabaaba'
    A: string='' matches rule 8
    A: string='abababaa' matches rule 8
    A: string='abababaaabbabbaa' matches rule 8
    B: string='aaaabaaaaaabaaba' matches rule 11
    does_match? string='bbabbbbbaaaabbbbaabbabbaabbbbbabaababbbababaaaab'
    A: string='' matches rule 8
    A: string='bbabbbbb' matches rule 8
    A: string='bbabbbbbaaaabbbb' matches rule 8
    B: string='abbbbbabaababbba' matches rule 11
    does_match? string='babaaabaaabaababbbaaaabb'
    A: string='' matches rule 8
    A: string='babaaaba' matches rule 8
    B: string='aabaababbbaaaabb' matches rule 11
    5

'' should not match 8

lol ok that was it, right answer was 381 :)

ok, starting on 20
i've parsed the input data into a list of these

    @dataclass
    class Tile:
        id: int
        # Borders are stored in the order (top, right, bottom, left).
        borders: tuple[str, str, str, str]
        data: list[str]

an interior tile must have all four borders be matched by surrounding tiles
an exterior tile must have two or three borders be matched by surrounding tiles (two on corners, three on edges)

it should definitely be possible to use that info to match these guys up
just - where do we start?

maybe have a fn that takes the list of tiles as input and returns as output a list of matches,
where a match is like
    (tile_1_id, tile_1_border_index, tile_2_id, tile_2_border_index)
?

i was originally thinking of doing something w a bit more ceremony/structure but i wonder if a flat list like that would be fine
it'll have duplicates in each direction (eg it'll emit a match for (tile_1, tile_2) and another for (tile_2, tile_1))
but that seems ok to me?

i dunno, maybe it'd be better for it to return a dict of like
{
    tile_id: [(tile_border_index, matching_tile_id, matching_tile_border_index)]
}

that seems potentially more useful
let's just write it and see what the output data looks like when run on the sample dataset
kinda feels like the flat list is fine to start out with

ok, here's what we get on the sample data

    [Match(tile_1_id=2311,
        tile_1_border_index=3,
        tile_2_id=1951,
        tile_2_border_index=1),
    Match(tile_1_id=2311,
        tile_1_border_index=0,
        tile_2_id=1427,
        tile_2_border_index=2),
    Match(tile_1_id=1951,
        tile_1_border_index=1,
        tile_2_id=2311,
        tile_2_border_index=3),
    Match(tile_1_id=1951,
        tile_1_border_index=0,
        tile_2_id=2729,
        tile_2_border_index=2),
    Match(tile_1_id=1171,
        tile_1_border_index=0,
        tile_2_id=2473,
        tile_2_border_index=3),
    Match(tile_1_id=1427,
        tile_1_border_index=2,
        tile_2_id=2311,
        tile_2_border_index=0),
    Match(tile_1_id=1427,
        tile_1_border_index=0,
        tile_2_id=1489,
        tile_2_border_index=2),
    Match(tile_1_id=1427,
        tile_1_border_index=1,
        tile_2_id=2473,
        tile_2_border_index=2),
    Match(tile_1_id=1427,
        tile_1_border_index=3,
        tile_2_id=2729,
        tile_2_border_index=1),
    Match(tile_1_id=1489,
        tile_1_border_index=2,
        tile_2_id=1427,
        tile_2_border_index=0),
    Match(tile_1_id=1489,
        tile_1_border_index=3,
        tile_2_id=2971,
        tile_2_border_index=1),
    Match(tile_1_id=2473,
        tile_1_border_index=3,
        tile_2_id=1171,
        tile_2_border_index=0),
    Match(tile_1_id=2473,
        tile_1_border_index=2,
        tile_2_id=1427,
        tile_2_border_index=1),
    Match(tile_1_id=2971,
        tile_1_border_index=1,
        tile_2_id=1489,
        tile_2_border_index=3),
    Match(tile_1_id=2971,
        tile_1_border_index=2,
        tile_2_id=2729,
        tile_2_border_index=0),
    Match(tile_1_id=2729,
        tile_1_border_index=2,
        tile_2_id=1951,
        tile_2_border_index=0),
    Match(tile_1_id=2729,
        tile_1_border_index=1,
        tile_2_id=1427,
        tile_2_border_index=3),
    Match(tile_1_id=2729,
        tile_1_border_index=0,
        tile_2_id=2971,
        tile_2_border_index=2)]

looking good to me so far
so what do we do with that?

do we place interior tiles first or exterior tiles first?
does it matter?

i'm thinking about several things at once including:
    what can we do if we just examine exterior tiles to start off?
    what will the structure of the placement algo be? recursive or while-true? operating until unplaced_tiles=[], right?

what are the properties of placed tiles? (TODO come back later and verify i've implemented these properties)
    their (x, y) location is known (will have to start tracking this somewhere)
    their borders are now in (north, east, south, west) order
    their data is now in the correct orientation

how will we bootstrap this process? ie how will we place the first 2 tiles?
    we'll pick the first tile in our list and try to place it with all other tiles,
        for each possible rotation of this tile / other tile

i still don't know if i should go outside-in or inside-out
maybe it doesn't matter

each round of the algorithm will have to consider (placed_tiles, unplaced_tiles, matches)
    the goal is to compute, for each tile under examination: (x, y, num_times_to_rotate_tile_to_the_right)

hm
one risk that comes to mind if we start with an edge
is that we might not get the orientation right -
it won't be possible to know until later on whether two edges should be going up, down, left, or right
that's really the case for just about everything
hm

this might be a bit more involved than i'd thought

well actually no
the orientation of the final image can be arbitrary, all that matters is that we connect all the tiles together
it doesn't matter if the final image is sideways or upside down, bc we just want the ids of the four corners

hm hm
looking back at my matches from before, i'm comparing them to what the sample data's final image should look like
    1951    2311    3079
    2729    1427    2473
    2971    1489    1171

my matches don't have a single match for 3079, for instance
i think i might need to compare tile.border to other_tile.border AND other_tile.border.reversed

    [Match(tile_1_id=2311,
        tile_1_border_index=3,
        tile_2_id=1951,
        tile_2_border_index=1),
    Match(tile_1_id=2311,
        tile_1_border_index=0,
        tile_2_id=1427,
        tile_2_border_index=2),
    Match(tile_1_id=2311,
        tile_1_border_index=1,
        tile_2_id=3079,
        tile_2_border_index=3),
    Match(tile_1_id=1951,
        tile_1_border_index=1,
        tile_2_id=2311,
        tile_2_border_index=3),
    Match(tile_1_id=1951,
        tile_1_border_index=0,
        tile_2_id=2729,
        tile_2_border_index=2),
    Match(tile_1_id=1171,
        tile_1_border_index=1,
        tile_2_id=1489,
        tile_2_border_index=1),
    Match(tile_1_id=1171,
        tile_1_border_index=0,
        tile_2_id=2473,
        tile_2_border_index=3),
    Match(tile_1_id=1427,
        tile_1_border_index=2,
        tile_2_id=2311,
        tile_2_border_index=0),
    Match(tile_1_id=1427,
        tile_1_border_index=0,
        tile_2_id=1489,
        tile_2_border_index=2),
    Match(tile_1_id=1427,
        tile_1_border_index=1,
        tile_2_id=2473,
        tile_2_border_index=2),
    Match(tile_1_id=1427,
        tile_1_border_index=3,
        tile_2_id=2729,
        tile_2_border_index=1),
    Match(tile_1_id=1489,
        tile_1_border_index=1,
        tile_2_id=1171,
        tile_2_border_index=1),
    Match(tile_1_id=1489,
        tile_1_border_index=2,
        tile_2_id=1427,
        tile_2_border_index=0),
    Match(tile_1_id=1489,
        tile_1_border_index=3,
        tile_2_id=2971,
        tile_2_border_index=1),
    Match(tile_1_id=2473,
        tile_1_border_index=3,
        tile_2_id=1171,
        tile_2_border_index=0),
    Match(tile_1_id=2473,
        tile_1_border_index=2,
        tile_2_id=1427,
        tile_2_border_index=1),
    Match(tile_1_id=2473,
        tile_1_border_index=1,
        tile_2_id=3079,
        tile_2_border_index=2),
    Match(tile_1_id=2971,
        tile_1_border_index=1,
        tile_2_id=1489,
        tile_2_border_index=3),
    Match(tile_1_id=2971,
        tile_1_border_index=2,
        tile_2_id=2729,
        tile_2_border_index=0),
    Match(tile_1_id=2729,
        tile_1_border_index=2,
        tile_2_id=1951,
        tile_2_border_index=0),
    Match(tile_1_id=2729,
        tile_1_border_index=1,
        tile_2_id=1427,
        tile_2_border_index=3),
    Match(tile_1_id=2729,
        tile_1_border_index=0,
        tile_2_id=2971,
        tile_2_border_index=2),
    Match(tile_1_id=3079,
        tile_1_border_index=3,
        tile_2_id=2311,
        tile_2_border_index=1),
    Match(tile_1_id=3079,
        tile_1_border_index=2,
        tile_2_id=2473,
        tile_2_border_index=1)]

yeah, now i have the right number of entries for 3079
nice!

ok so anyway
so i have a list of tiles and a list of matches
and i need to place them
i guess you could place any corner at (0, 0) and go from there
its default orientation can be authoritative bc the resulting image's orientation doesn't matter
works for me!

wait wait let's back up one more time
why exactly can't i just figure out what the four corners are immediately and give aoc their ids?

yeah uh i can just do that

    def find_corners(tiles: list[Tile]) -> list[Tile]:
        matches = find_matches(tiles)
        return [
            tile
            for tile in tiles
            if len([match for match in matches if match.tile_1_id == tile.id]) == 2
        ]


    def part_1() -> int:
        tiles = load_input()
        return reduce(lambda x, y: x * y, [tile.id for tile in find_corners(tiles)])

lol yeah ok that does solve part 1 but for part 2 you do need the full image, which is what i was expecting so no big surprise
so let's stick with part 1 for now and keep working on filling in the image

making good progress so far
so the trickiest thing in rotating a tile to the right is rotating its data

    Tile(id=2003,
        borders=('..#.#....#', '##....#.##', '..#####..#', '..#####.#.'),
        data=['..#.#....#', '.##..#...#', '#.........', '#.........', '#.........', '#.##...#..', '#..#..##.#', '.......#..', '##.......#', '..#####..#'])

so data[0] should be along the right border, data[1] should be second-from-right, etc
i think i can do that

ok, let's take a look

    rotating
    tile.data=['..#.#....#', '.##..#...#', '#.........', '#.........', '#.........', '#.##...#..', '#..#..##.#', '.......#..', '##.......#', '..#####..#']
    rotate_tile_right(tile).data=['#....#.#..', '#...#..##.', '.........#', '.........#', '.........#', '..#...##.#', '#.##..#..#', '..#.......', '#.......##', '#..#####..']
    rotating
    tile.data=['#....#.#..', '#...#..##.', '.........#', '.........#', '.........#', '..#...##.#', '#.##..#..#', '..#.......', '#.......##', '#..#####..']
    rotate_tile_right(tile).data=['..#.#....#', '.##..#...#', '#.........', '#.........', '#.........', '#.##...#..', '#..#..##.#', '.......#..', '##.......#', '..#####..#']
    rotating
    tile.data=['..#.#....#', '.##..#...#', '#.........', '#.........', '#.........', '#.##...#..', '#..#..##.#', '.......#..', '##.......#', '..#####..#']
    rotate_tile_right(tile).data=['#....#.#..', '#...#..##.', '.........#', '.........#', '.........#', '..#...##.#', '#.##..#..#', '..#.......', '#.......##', '#..#####..']

ugh let's just write a print fn rq

    rotating
    Tile 2003:

    ..#.#....#
    .##..#...#
    #.........
    #.........
    #.........
    #.##...#..
    #..#..##.#
    .......#..
    ##.......#
    ..#####..#

    Tile 2003:

    #....#.#..
    #...#..##.
    .........#
    .........#
    .........#
    ..#...##.#
    #.##..#..#
    ..#.......
    #.......##
    #..#####..

no, i dont think i did this right yet
i think i just accidentally reversed each line somehow??

ok how about this

    rotating

    Tile 2003:

    ..#.#....#
    .##..#...#
    #.........
    #.........
    #.........
    #.##...#..
    #..#..##.#
    .......#..
    ##.......#
    ..#####..#

    Tile 2003:

    .#.#####..
    .#......#.
    #...#...##
    #..##.....
    #........#
    #.......#.
    #..#......
    ..###.....
    ..........
    ##.#....##

ok that looks good!!!

ok so now i have an initial pass at tile placement working
but the first time i run it i notice this:

    (Pdb) relevant_matches
    [Match(tile_1_id=1361, tile_1_border_index=0, tile_2_id=3517,
    tile_2_border_index=0), Match(tile_1_id=2003, tile_1_border_index=0,
    tile_2_id=3517, tile_2_border_index=3)]

    (Pdb) tile
    Tile(id=3517, borders=('###..##.#.', '.####.#.##', '........##', '#....#.#..'),
    data=['###..##.#.', '...###...#', '..#......#', '.#.#...#.#', '....#.##.#',
    '#...#..#..', '...##....#', '#.....###.', '.#..##...#', '........##'])

    (Pdb) placed_tiles
    {(0, 0): Tile(id=1327, borders=('..##..#..#', '##....#.##', '#..#.##.##',
    '..##..#..#'), data=['##.##.#..#', '#..#.###..', '..#....##.', '#........#',
    '.....#.#..', '..#.......', '..#..#...#', '.#.#..#..#', '#.#.......',
    '#####.###.']), (-1, 0): Tile(id=2003, borders=('..#####.#.', '##....#.##',
    '..#####..#', '..#####.#.'), data=['##....#.##', '..........', '.....###..',
    '......#..#', '.#.......#', '#........#', '.....##..#', '##...#...#',
    '.#......#.', '..#####.#.']), (0, 1): Tile(id=1559, borders=('##.##.#..#',
    '#..##.#.#.', '#....#..#.', '#.#.##...#'), data=['##.##.#..#', '.....#.#..',
    '#.#.####..', '...#.#...#', '##....#..#', '#.##...#..', '.#..##.###',
    '....#..#..', '.#.#.#.#.#', '#....#..#.']), (0, -1): Tile(id=1361,
    borders=('....#.###.', '#####.###.', '.##..##...', '....#.###.'),
    data=['.###.#....', '#..##.#..#', '###..#....', '..###....#', '...#...#.#',
    '#.........', '#.#.#..##.', '....#....#', '..#..#...#', '.###.#####'])}

relevant_matches is suspicious in a bad way - two different placed tiles say that `tile` borders them to the north!
that's really bad!!

i'll start off by checking my rotate-to-the-right fn

i notice this:

    rotating 2003 to the right
    rotating 2003 to the right
    rotating 2003 to the right
    rotating 1327 to the right
    rotating 1327 to the right
    rotating 1361 to the right

let's take another look at tile 2003

    Tile(id=2003, borders=('..#####.#.', '##....#.##', '..#####..#', '..#####.#.'),
    data=['##....#.##', '..........', '.....###..',
        '......#..#', '.#.......#', '#........#', '.....##..#', '##...#...#',
        '.#......#.', '..#####.#.'])

those borders don't look right to me

    rotating 2003 to the right
    borders before: ('..#.#....#', '##....#.##', '..#####..#', '..#####.#.')
    borders after: ('..#####.#.', '##....#.##', '..#####..#', '..#####.#.')
    rotating 2003 to the right
    borders before: ('..#####.#.', '##....#.##', '..#####..#', '..#####.#.')
    borders after: ('..#####.#.', '##....#.##', '..#####..#', '..#####.#.')
    rotating 2003 to the right
    borders before: ('..#####.#.', '##....#.##', '..#####..#', '..#####.#.')
    borders after: ('..#####.#.', '##....#.##', '..#####..#', '..#####.#.')

oh i'm stupid

        id=tile.id, borders=(tile.borders[-1],) + tile.borders[1:], data=rotated_data

should be

        id=tile.id, borders=(tile.borders[-1],) + tile.borders[:3], data=rotated_data

ok so end result

    Tile(id=2003, borders=('##....#.##', '..#####..#', '..#####.#.', '..#.#....#'),
        data=['##....#.##', '..........', '.....###..', '......#..#', '.#.......#',
        '#........#', '.....##..#', '##...#...#', '.#......#.', '..#####.#.'])

those borders still don't match the rotated data

    Tile(id=2003, borders=('##....#.##', '#..#####..', '..#####.#.', '#....#.#..'),
        data=['##....#.##', '..........', '.....###..', '......#..#', '.#.......#',
        '#........#', '.....##..#', '##...#...#', '.#......#.', '..#####.#.'])

ok that looks better to me

now let's see what our multiple-relevant-matches data looks like

    (Pdb) relevant_matches
    [Match(tile_1_id=1327, tile_1_border_index=2, tile_2_id=1361,
    tile_2_border_index=1), Match(tile_1_id=1327, tile_1_border_index=0,
    tile_2_id=1361, tile_2_border_index=1)]

the incoming tile borders one tile on the south and another on the north
looks good to me!!!

ok so when i run my program and print(len(placed_tiles), len(unplaced_tiles))
i see

    1 143
    2 143
    3 143
    4 143
    4 142
    5 141
    6 140
    7 139
    8 139
    8 138
    etc

which is indicating to me that i'm overwriting positions in placed_tiles